{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'diving': 0, 'tennis': 9, 'walk': 10, 'biking': 1, 'golf': 2, 'juggle': 3, 'jumping': 4, 'riding': 5, 'shooting': 6, 'spiking': 7, 'swing': 8}\n",
      "successfully,len(train_list) 954\n",
      "successfully,len(test_list) 645\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "WARNING:tensorflow:From C:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-1-5a0f2fa89cc9>:149: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-1-5a0f2fa89cc9>:150: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:At least two cells provided to MultiRNNCell are the same object and will share weights.\n",
      "WARNING:tensorflow:From <ipython-input-1-5a0f2fa89cc9>:152: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From <ipython-input-1-5a0f2fa89cc9>:156: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From <ipython-input-1-5a0f2fa89cc9>:185: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-1-5a0f2fa89cc9>:198: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Tensor(\"add_3:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:From C:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/160 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_read_time: 0.36 s\n"
     ]
    },
    {
     "ename": "AlreadyExistsError",
     "evalue": "Resource __per_step_2/gradients/rnn/while/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/BiasAdd/Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/struct tensorflow::TemporaryVariableOp::TmpVar\n\t [[{{node gradients/rnn/while/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/BiasAdd/Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAlreadyExistsError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mC:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAlreadyExistsError\u001b[0m: Resource __per_step_2/gradients/rnn/while/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/BiasAdd/Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/struct tensorflow::TemporaryVariableOp::TmpVar\n\t [[{{node gradients/rnn/while/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/BiasAdd/Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAlreadyExistsError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5a0f2fa89cc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[0mconv_img\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mbatch_conv_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[0mys\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m             \u001b[0mLr\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         })\n\u001b[0;32m    282\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msecond\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAlreadyExistsError\u001b[0m: Resource __per_step_2/gradients/rnn/while/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/BiasAdd/Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var/struct tensorflow::TemporaryVariableOp::TmpVar\n\t [[{{node gradients/rnn/while/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/BiasAdd/Enter_grad/ArithmeticOptimizer/AddOpsRewrite_Add/tmp_var}}]]"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "from __future__ import division\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import glob\n",
    "import sys\n",
    "import h5py \n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from conv_cell import ConvLSTMCell\n",
    "from fc_attention import fc_attention_sum,fc_attention\n",
    "from conv_attention import conv_attention_sum,conv_attention\n",
    "\n",
    "########################################################################\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "conv_img_features = \"/your_dir/ucf11_features/image_pool5/\"\n",
    "fc_img_features = \"/your_dir/ucf11_features/image_fc6/\"\n",
    "\n",
    "\n",
    "train_list = \"C:\\\\Users\\\\user\\\\Desktop\\\\git\\\\DTA\\\\ucf11TrainTestlist\\\\ucf11_train.txt\"\n",
    "test_list = \"C:\\\\Users\\\\user\\\\Desktop\\\\git\\\\DTA\\\\ucf11TrainTestlist\\\\ucf11_test.txt\"\n",
    "classInd = \"C:\\\\Users\\\\user\\\\Desktop\\\\git\\\\DTA\\\\ucf11TrainTestlist\\\\classInd.txt\"\n",
    "\n",
    "batch_size = 6\n",
    "n_inputs = 4096   \n",
    "n_steps = 40    \n",
    "n_hidden_units = filters = 1024\n",
    "fc_attention_size = 50\n",
    "n_classes = 11\n",
    "n_layers = 2\n",
    "scale = 1\n",
    "n_num =10\n",
    "\n",
    "timesteps = num_frames = 40\n",
    "shape_1 = [7, 7]\n",
    "shape_2 = [5, 10]\n",
    "kernel = [3, 3]\n",
    "channels = 512\n",
    "attention_kernel = [1,1]\n",
    "basic_lr = 0.0001\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "g = open(classInd,\"r\")\n",
    "labels = sorted(g.readlines())\n",
    "nums = []\n",
    "names = []\n",
    "for label in labels:\n",
    "  a = label.split(\" \")\n",
    "  nums.append(int(a[0])-1)\n",
    "  names.append(a[1][:-1])\n",
    "label_dict = dict(zip(names,nums))\n",
    "print(label_dict)\n",
    "\n",
    "\n",
    "train_lines = []\n",
    "f = open(train_list,\"r\")  \n",
    "lines_ = f.readlines()\n",
    "for i in range(len(lines_)//scale):\n",
    "  train_lines.append(lines_[i*scale])\n",
    "len_train = len(train_lines)\n",
    "print(\"successfully,len(train_list)\",len_train)\n",
    "random.shuffle(train_lines)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "h = open(test_list,\"r\")  \n",
    "test_lines_ = sorted(h.readlines())\n",
    "test_lines = [] \n",
    "for i in range(len(test_lines_)//scale):\n",
    "  test_lines.append(test_lines_[i*scale])\n",
    "len_test = len(test_lines)\n",
    "print(\"successfully,len(test_list)\",len_test)\n",
    "\n",
    "\n",
    "\n",
    "test_labels = []\n",
    "ground_labels = []\n",
    "for test_video in test_lines:\n",
    "    video_class = str(test_video.split(\" \")).split(\"_\")[1]\n",
    "    ground_label = label_dict[video_class]\n",
    "    test_labels.append(ground_label)\n",
    "\n",
    "print(test_labels)\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "\n",
    "def fc_feature(video_name):\n",
    "    g = h5py.File(fc_img_features+video_name)\n",
    "    img_features = g['video_feature']\n",
    "    img_features = img_features[:]\n",
    "    g.close()\n",
    "    return img_features\n",
    "\n",
    "\n",
    "def conv_feature(video_name):\n",
    "    g = h5py.File(conv_img_features+video_name)\n",
    "    img_features = g['video_feature']\n",
    "    img_features = img_features[:]\n",
    "    g.close()\n",
    "    return img_features\n",
    "\n",
    "\n",
    "def accuracy(a,b):\n",
    "    c = np.equal(a,b).astype(float)\n",
    "    acc = sum(c)/len(c)\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "def compute_score_loss(batch_fc_img,batch_conv_img,batch_labels):\n",
    "    global fc_pred\n",
    "    global conv_pred\n",
    "    global loss\n",
    "    fc_score,conv_score,video_loss =  sess.run([fc_pred,conv_pred,loss], feed_dict={\n",
    "            fc_img : batch_fc_img,\n",
    "            conv_img: batch_conv_img,\n",
    "            ys : batch_labels\n",
    "            })\n",
    "    return fc_score,conv_score,video_loss\n",
    "#################################################################################\n",
    "fc_img = tf.placeholder(tf.float32, [None, 40, 4096]) \n",
    "\n",
    "conv_img = tf.placeholder(tf.float32, [None, timesteps] + shape_1 + [channels]) \n",
    "\n",
    "\n",
    "\n",
    "ys = tf.placeholder(tf.float32, [None, n_classes])\n",
    "Lr = tf.placeholder(tf.float32) \n",
    "\n",
    "\n",
    "def FC_LSTM(X_spa,attention):\n",
    "    weights_img = tf.Variable(tf.random_normal([n_inputs, n_hidden_units]))\n",
    "    biases_img = tf.Variable(tf.constant(0.1, shape=[n_hidden_units, ]))\n",
    "\n",
    "\n",
    "    X_spa = tf.reshape(X_spa, [n_num*batch_size*n_steps, n_inputs])\n",
    "    X_spa = tf.matmul(X_spa, weights_img) + biases_img\n",
    "    X_spa = tf.reshape(X_spa, [-1, n_steps, n_hidden_units])\n",
    "\n",
    "\n",
    "    cell_spa = tf.contrib.rnn.BasicLSTMCell(n_hidden_units)\n",
    "    mlstm_cell_spa = tf.contrib.rnn.MultiRNNCell([cell_spa for _ in range(n_layers)], state_is_tuple=True)     \n",
    "    init_state_spa = mlstm_cell_spa.zero_state(n_num*batch_size, dtype=tf.float32)\n",
    "    outputs_spa, final_state_spa = tf.nn.dynamic_rnn(mlstm_cell_spa, X_spa, initial_state=init_state_spa, time_major=False)\n",
    "    \n",
    "    attention_output_spa = fc_attention_sum(outputs_spa, fc_attention_size)\n",
    "    if attention == True:\n",
    "        attention_output_spa = tf.layers.batch_normalization(attention_output_spa)\n",
    "        return attention_output_spa\n",
    "    else:\n",
    "        outputs_spa = tf.layers.batch_normalization(outputs_spa)\n",
    "        outputs_spa = tf.reduce_sum(outputs_spa,axis = 1)\n",
    "        return outputs_spa\n",
    "\n",
    "def CONV_LSTM(conv_img,shape,attention):\n",
    "    img_cell = ConvLSTMCell(shape, filters, kernel)\n",
    "    img_outputs, img_state = tf.nn.dynamic_rnn(img_cell, conv_img, dtype=conv_img.dtype, time_major=True)\n",
    "    if attention == True: \n",
    "        img_attention_output = conv_attention_sum(img_outputs, attention_kernel)#[B*H*W*C]\n",
    "        img_attention_output = tf.layers.batch_normalization(img_attention_output)\n",
    "        return img_attention_output\n",
    "    else:\n",
    "        img_outputs = tf.layers.batch_normalization(img_outputs)\n",
    "        img_outputs = tf.reduce_sum(img_outputs,axis = 1)\n",
    "        return img_outputs  \n",
    "\n",
    "def FC_layer(inputs):\n",
    "    weights2 =  tf.get_variable(\"weights2\", [n_hidden_units, n_classes],initializer=tf.truncated_normal_initializer())\n",
    "    biases2 = tf.get_variable(\"biases2\", [n_classes],initializer=tf.truncated_normal_initializer())\n",
    "    result = tf.nn.dropout((tf.matmul(inputs, weights2) + biases2), 0.5)\n",
    "    return result\n",
    "\n",
    "fc_img_out = FC_LSTM(fc_img, True)\n",
    "\n",
    "conv_img_out = CONV_LSTM(conv_img, shape_1,True)\n",
    "\n",
    "fc_img_drop = tf.nn.dropout(fc_img_out, 0.5)\n",
    "conv_img_drop = tf.nn.dropout(conv_img_out, 0.5)\n",
    "conv_img_drop = tf.nn.max_pool(conv_img_drop,[1,7,7,1],[1,1,1,1],padding='VALID')\n",
    "conv_img_drop = tf.reshape(conv_img_drop,[-1,filters])\n",
    "\n",
    "with tf.variable_scope(\"FC\"):\n",
    "    fc_result = FC_layer(fc_img_drop)\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    conv_result = FC_layer(conv_img_drop)\n",
    "\n",
    "fc_pred = tf.nn.softmax(fc_result)\n",
    "conv_pred = tf.nn.softmax(conv_result)\n",
    "\n",
    "fc_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=fc_result, labels=ys))\n",
    "conv_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=conv_result, labels=ys))\n",
    "loss = fc_loss+conv_loss\n",
    "print(loss)\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(Lr).minimize(loss)\n",
    "\n",
    "config = tf.ConfigProto() \n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "if not os.path.exists('fc+conv_lstm_tmp_attention'):\n",
    "    os.mkdir('fc+conv_lstm_tmp_attention/')\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "init_op = tf.global_variables_initializer() \n",
    "sess.run(init_op)\n",
    "\n",
    "############################################start_training###########################################\n",
    "\n",
    "\n",
    "k = 0\n",
    "u = 0\n",
    "\n",
    "full_loss = []\n",
    "for l in range(1000):\n",
    "    lr = basic_lr\n",
    "    pbar = tqdm(total=((len_train//batch_size)+1))\n",
    "    for i in range((len_train//batch_size)+1):\n",
    "\n",
    "        batch_fc_img = np.zeros((10*batch_size,40,4096),dtype = np.float32)\n",
    "        batch_conv_img = np.zeros((10*batch_size,40,7,7,512),dtype = np.float32)\n",
    "        batch_labels = np.zeros((10*batch_size,n_classes),dtype = np.int8)\n",
    "\n",
    "\n",
    "        time1 = time.time()\n",
    "        k= 0\n",
    "        for j in range(i*batch_size,(i+1)*batch_size):\n",
    "            if j>=len_train:\n",
    "                j = random.randint(0,len_train-1)\n",
    "            one_hot=np.zeros((n_classes),dtype = np.int8)\n",
    "            line = train_lines[j]\n",
    "\n",
    "            video_name = line.split(\" \")[0]\n",
    "\n",
    "            video_class = str(line.split(\" \")[0]).split(\"_\")[1]\n",
    "            feature_name = video_name+\"_.h5\"\n",
    "\n",
    "\n",
    "            one_hot[label_dict[video_class]] = 1\n",
    "            label = np.expand_dims(one_hot,axis = 0)\n",
    "            label = label.repeat(10,axis=0)\n",
    "          \n",
    "            #fc_img_fea = fc_feature(feature_name)\n",
    "            import tensorflow as tf\n",
    "            fc_img_fea=tf.random_uniform([1,40,4096], minval=1.0, maxval=5.0, dtype=tf.float32)\n",
    "            fc_img_fea=np.random.randn(1,40,4096)\n",
    "            #conv_img_fea = conv_feature(feature_name)\n",
    "            conv_img_fea=tf.random_uniform([1,timesteps]+shape_1+[channels], minval=1.0, maxval=5.0, dtype=tf.float32)\n",
    "            conv_img_fea=np.random.randn(1,timesteps,shape_1[0],shape_1[1],channels)\n",
    "\n",
    "\n",
    "            #fc_img_fea = np.transpose(fc_img_fea,(1,0,2))\n",
    "            #conv_img_fea = np.transpose(conv_img_fea,(1,0,3,4,2))\n",
    "\n",
    "\n",
    "            batch_fc_img[n_num*k:n_num*k+n_num] = fc_img_fea\n",
    "    \n",
    "            batch_conv_img[n_num*k:n_num*k+n_num] = conv_img_fea\n",
    "            batch_labels[n_num*k:n_num*k+n_num] = label\n",
    "            k = k+1\n",
    "        time2 = time.time()\n",
    "        print(\"batch_read_time:\", '{0:.2f}'.format(time2-time1),\"s\")\n",
    "        k = k+1\n",
    "\n",
    "        loss_,_,first,second = sess.run([loss,train_op,fc_img_out,fc_img_out], feed_dict={\n",
    "            fc_img : batch_fc_img,\n",
    "            conv_img : batch_conv_img,\n",
    "            ys : batch_labels,\n",
    "            Lr : lr\n",
    "        })\n",
    "        print(first,second)\n",
    "        print(\"batch_loss:\",loss_)\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "    model_name = \"fc+conv_lstm_tmp_attention/\"+str(l)+\"epoch_model.ckpt\"\n",
    "    saver.save(sess, model_name)\n",
    "\n",
    "    print(\"successfully,start_test!\")\n",
    "\n",
    "############################################################################################\n",
    "    pbar = tqdm(total=((len_test//batch_size)+1))\n",
    "    fc_scores = []\n",
    "    conv_scores = []\n",
    "    for i in range((len_test//batch_size)+1):\n",
    "        batch_fc_img = np.zeros((n_num*batch_size,40,4096),dtype = np.float32)\n",
    "        batch_conv_img = np.zeros((n_num*batch_size,40,7,7,512),dtype = np.float32)\n",
    "        batch_labels = np.zeros((n_num*batch_size,n_classes),dtype = np.int8)\n",
    "\n",
    "        time1 = time.time()\n",
    "        k= 0\n",
    "        for j in range(i*batch_size,(i+1)*batch_size):\n",
    "            if j>=len_test:\n",
    "                j = random.randint(0,len_test-1)\n",
    "            one_hot=np.zeros((n_classes),dtype = np.int8)\n",
    "            line = test_lines[j]\n",
    "            video_class = str(line.split(\" \")[0]).split(\"_\")[1]\n",
    "            feature_name = line.split(\" \")[0]+\"_.h5\"\n",
    "\n",
    "\n",
    "            one_hot[label_dict[video_class]] = 1\n",
    "            label = np.expand_dims(one_hot,axis = 0)\n",
    "            label = label.repeat(10,axis=0)\n",
    "\n",
    "            conv_img_fea = conv_feature(feature_name)\n",
    "            conv_img_fea = np.transpose(conv_img_fea,(1,0,3,4,2))\n",
    "\n",
    "            fc_img_fea = fc_feature(feature_name)\n",
    "            fc_img_fea = np.transpose(fc_img_fea,(1,0,2))\n",
    "\n",
    "            batch_fc_img[n_num*k:n_num*k+n_num] = fc_img_fea\n",
    "            batch_conv_img[n_num*k:n_num*k+n_num] = conv_img_fea\n",
    "            batch_labels[n_num*k:n_num*k+n_num] = label\n",
    "            k = k+1\n",
    "        test_fc_score, test_conv_score, test_loss = compute_score_loss(batch_fc_img,batch_conv_img,batch_labels)\n",
    "        print(\"test_loss:\",test_loss)\n",
    "        test_fc_score = np.sum(np.reshape(np.array(test_fc_score),(batch_size,n_num,n_classes)),axis=1)    #(batch_size, n_classes)\n",
    "        test_conv_score = np.sum(np.reshape(np.array(test_conv_score),(batch_size,n_num,n_classes)),axis=1) \n",
    "    \n",
    "        fc_scores.append(test_fc_score)\n",
    "        conv_scores.append(test_conv_score)\n",
    "        pbar.update(1)\n",
    "    fc_scores = np.reshape(np.array(fc_scores),(-1,n_classes))[:len_test]\n",
    "    conv_scores = np.reshape(np.array(conv_scores),(-1,n_classes))[:len_test]\n",
    "\n",
    "    print(fc_scores.shape)\n",
    "    print(conv_scores.shape)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    num_test_score = fc_scores\n",
    "    test_label_pred = np.argmax(num_test_score,axis = 1)\n",
    "    print(test_label_pred.shape)\n",
    "    print(l,\"epoch:, attention，Fc_lstm_ACC:\",accuracy(test_label_pred,test_labels))\n",
    "    test_info = []\n",
    "    for i in range(len_test):\n",
    "      video_info = []\n",
    "      video_info.append(num_test_score[i])\n",
    "      video_info.append(test_labels[i])\n",
    "      test_info.append(video_info)\n",
    "      \n",
    "    npz_name = \"score_attention/\"+str(l)+\"_epoch_fc_score.npz\"\n",
    "    np.savez(npz_name, test_info=test_info)\n",
    "\n",
    "    num_test_score = conv_scores\n",
    "    test_label_pred = np.argmax(num_test_score,axis = 1)\n",
    "    print(test_label_pred.shape)\n",
    "    print(l,\"epoch:, attention，Conv_lstm_ACC:\",accuracy(test_label_pred,test_labels))\n",
    "    test_info = []\n",
    "    for i in range(len_test):\n",
    "      video_info = []\n",
    "      video_info.append(num_test_score[i])\n",
    "      video_info.append(test_labels[i])\n",
    "      test_info.append(video_info)\n",
    "      \n",
    "    npz_name = \"score_attention/\"+str(l)+\"_epoch_conv_score.npz\"\n",
    "    np.savez(npz_name, test_info=test_info)\n",
    "\n",
    "    num_test_score = np.add(fc_scores,conv_scores)\n",
    "    test_label_pred = np.argmax(num_test_score,axis = 1)\n",
    "    print(test_label_pred.shape)\n",
    "    print(l,\"epoch:, attention，Add_fusion_ACC:\",accuracy(test_label_pred,test_labels))\n",
    "    test_info = []\n",
    "    for i in range(len_test):\n",
    "      video_info = []\n",
    "      video_info.append(num_test_score[i])\n",
    "      video_info.append(test_labels[i])\n",
    "      test_info.append(video_info)\n",
    "      \n",
    "    npz_name = \"score_attention/\"+str(l)+\"_epoch_numscore.npz\"\n",
    "    np.savez(npz_name, test_info=test_info)\n",
    "\n",
    "    mul_test_score = np.multiply(fc_scores,conv_scores)\n",
    "    test_label_pred = np.argmax(mul_test_score,axis = 1)\n",
    "    print(test_label_pred.shape)\n",
    "    print(l,\"epoch:, attention，Mul_fusion_ACC:\",accuracy(test_label_pred,test_labels))\n",
    "    test_info = []\n",
    "    for i in range(len_test):\n",
    "      video_info = []\n",
    "      video_info.append(mul_test_score[i])\n",
    "      video_info.append(test_labels[i])\n",
    "      test_info.append(video_info)\n",
    "      \n",
    "    npz_name = \"score_attention/\"+str(l)+\"_epoch_mulscore.npz\"\n",
    "    np.savez(npz_name, test_info=test_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randn(1,40,4096).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
