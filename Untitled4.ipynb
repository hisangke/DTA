{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'diving': 0, 'tennis': 9, 'walk': 10, 'biking': 1, 'golf': 2, 'juggle': 3, 'jumping': 4, 'riding': 5, 'shooting': 6, 'spiking': 7, 'swing': 8}\n",
      "successfully,len(train_list) 954\n",
      "successfully,len(test_list) 645\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable rnn/basic_convlstm_cell/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"C:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-eec1a3c897a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;31m#fc_img_out = FC_LSTM(fc_img, True) #(60,1024)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m \u001b[0mconv_img_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCONV_LSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#(60,1024)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;31m#fc_img_drop = tf.nn.dropout(fc_img_out, 0.5)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-eec1a3c897a3>\u001b[0m in \u001b[0;36mCONV_LSTM\u001b[1;34m(conv_img, shape, attention)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[0mimg_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConvLSTMCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;31m#conv_img shape (?, 40, 7, 7, 512)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[0mimg_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_cell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconv_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_major\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m     \u001b[1;31m#img_outputs shape (?, 40, 7, 7, 1024)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;31m#attention_kernel shape (1,1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[1;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m         dtype=dtype)\n\u001b[0m\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[1;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[1;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[0;32m    877\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m       swap_memory=swap_memory)\n\u001b[0m\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m   \u001b[1;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[0;32m   3554\u001b[0m       \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3555\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[1;32m-> 3556\u001b[1;33m                                     return_same_structure)\n\u001b[0m\u001b[0;32m   3557\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3558\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[1;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[0;32m   3085\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3086\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[1;32m-> 3087\u001b[1;33m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[0;32m   3088\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3089\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[1;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[0;32m   3020\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[0;32m   3021\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3022\u001b[1;33m     \u001b[0mbody_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3023\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3024\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(i, lv)\u001b[0m\n\u001b[0;32m   3523\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[0;32m   3524\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[1;32m-> 3525\u001b[1;33m         \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3527\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[1;34m(time, output_ta_t, state)\u001b[0m\n\u001b[0;32m    845\u001b[0m           skip_conditionals=True)\n\u001b[0;32m    846\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m       \u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m     \u001b[1;31m# Keras cells always wrap state as list, even if it's a single tensor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    831\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_keras_rnn_cell\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m       \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m     \u001b[0mcall_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\git\\DTA\\conv_cell.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, state, scope)\u001b[0m\n\u001b[0;32m     51\u001b[0m       \u001b[0mconcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m       \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'kernel'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_kernel_size\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minp_channel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_channel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m       \u001b[0mconcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SAME'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1477\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1478\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1479\u001b[1;33m       aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1218\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1220\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32mC:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    545\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32mC:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    497\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[1;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    846\u001b[0m         \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"tensorflow/python\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" % (err_msg, \"\".join(\n\u001b[1;32m--> 848\u001b[1;33m             traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    849\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable rnn/basic_convlstm_cell/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"C:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\soft\\install\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "from __future__ import division\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import glob\n",
    "import sys\n",
    "import h5py \n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from conv_cell import ConvLSTMCell\n",
    "from fc_attention import fc_attention_sum,fc_attention\n",
    "from conv_attention import conv_attention_sum,conv_attention\n",
    "\n",
    "########################################################################\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "conv_img_features = \"/your_dir/ucf11_features/image_pool5/\"\n",
    "fc_img_features = \"/your_dir/ucf11_features/image_fc6/\"\n",
    "\n",
    "\n",
    "train_list = \"C:\\\\Users\\\\user\\\\Desktop\\\\git\\\\DTA\\\\ucf11TrainTestlist\\\\ucf11_train.txt\"\n",
    "test_list = \"C:\\\\Users\\\\user\\\\Desktop\\\\git\\\\DTA\\\\ucf11TrainTestlist\\\\ucf11_test.txt\"\n",
    "classInd = \"C:\\\\Users\\\\user\\\\Desktop\\\\git\\\\DTA\\\\ucf11TrainTestlist\\\\classInd.txt\"\n",
    "\n",
    "batch_size = 6\n",
    "n_inputs = 4096   \n",
    "n_steps = 40    \n",
    "n_hidden_units = filters = 1024\n",
    "fc_attention_size = 50\n",
    "n_classes = 11\n",
    "n_layers = 2\n",
    "scale = 1\n",
    "n_num =10\n",
    "\n",
    "timesteps = num_frames = 40\n",
    "shape_1 = [7, 7]\n",
    "shape_2 = [5, 10]\n",
    "kernel = [3, 3]\n",
    "channels = 512\n",
    "attention_kernel = [1,1]\n",
    "basic_lr = 0.0001\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "g = open(classInd,\"r\")\n",
    "labels = sorted(g.readlines())\n",
    "nums = []\n",
    "names = []\n",
    "for label in labels:\n",
    "  a = label.split(\" \")\n",
    "  nums.append(int(a[0])-1)\n",
    "  names.append(a[1][:-1])\n",
    "label_dict = dict(zip(names,nums))\n",
    "print(label_dict)\n",
    "\n",
    "\n",
    "train_lines = []\n",
    "f = open(train_list,\"r\")  \n",
    "lines_ = f.readlines()\n",
    "for i in range(len(lines_)//scale):\n",
    "  train_lines.append(lines_[i*scale])\n",
    "len_train = len(train_lines)\n",
    "print(\"successfully,len(train_list)\",len_train)\n",
    "random.shuffle(train_lines)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "h = open(test_list,\"r\")  \n",
    "test_lines_ = sorted(h.readlines())\n",
    "test_lines = [] \n",
    "for i in range(len(test_lines_)//scale):\n",
    "  test_lines.append(test_lines_[i*scale])\n",
    "len_test = len(test_lines)\n",
    "print(\"successfully,len(test_list)\",len_test)\n",
    "\n",
    "\n",
    "\n",
    "test_labels = []\n",
    "ground_labels = []\n",
    "for test_video in test_lines:\n",
    "    video_class = str(test_video.split(\" \")).split(\"_\")[1]\n",
    "    ground_label = label_dict[video_class]\n",
    "    test_labels.append(ground_label)\n",
    "\n",
    "print(test_labels)\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "\n",
    "def fc_feature(video_name):\n",
    "    g = h5py.File(fc_img_features+video_name)\n",
    "    img_features = g['video_feature']\n",
    "    img_features = img_features[:]\n",
    "    g.close()\n",
    "    return img_features\n",
    "\n",
    "\n",
    "def conv_feature(video_name):\n",
    "    g = h5py.File(conv_img_features+video_name)\n",
    "    img_features = g['video_feature']\n",
    "    img_features = img_features[:]\n",
    "    g.close()\n",
    "    return img_features\n",
    "\n",
    "\n",
    "def accuracy(a,b):\n",
    "    c = np.equal(a,b).astype(float)\n",
    "    acc = sum(c)/len(c)\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "def compute_score_loss(batch_fc_img,batch_conv_img,batch_labels):\n",
    "    global fc_pred\n",
    "    global conv_pred\n",
    "    global loss\n",
    "    fc_score,conv_score,video_loss =  sess.run([fc_pred,conv_pred,loss], feed_dict={\n",
    "            fc_img : batch_fc_img,\n",
    "            conv_img: batch_conv_img,\n",
    "            ys : batch_labels\n",
    "            })\n",
    "    return fc_score,conv_score,video_loss\n",
    "#################################################################################\n",
    "fc_img = tf.placeholder(tf.float32, [60, 40, 4096]) \n",
    "\n",
    "conv_img = tf.placeholder(tf.float32, [60, timesteps] + shape_1 + [channels]) \n",
    "\n",
    "\n",
    "\n",
    "ys = tf.placeholder(tf.float32, [60, n_classes])\n",
    "Lr = tf.placeholder(tf.float32) \n",
    "\n",
    "\n",
    "def FC_LSTM(X_spa,attention):\n",
    "    weights_img = tf.Variable(tf.random_normal([n_inputs, n_hidden_units]))\n",
    "    biases_img = tf.Variable(tf.constant(0.1, shape=[n_hidden_units, ]))\n",
    "\n",
    "\n",
    "    X_spa = tf.reshape(X_spa, [n_num*batch_size*n_steps, n_inputs])\n",
    "    X_spa = tf.matmul(X_spa, weights_img) + biases_img\n",
    "    X_spa = tf.reshape(X_spa, [-1, n_steps, n_hidden_units])\n",
    "\n",
    "\n",
    "    cell_spa = tf.contrib.rnn.BasicLSTMCell(n_hidden_units)\n",
    "    mlstm_cell_spa = tf.contrib.rnn.MultiRNNCell([cell_spa for _ in range(n_layers)], state_is_tuple=True)     \n",
    "    init_state_spa = mlstm_cell_spa.zero_state(n_num*batch_size, dtype=tf.float32)\n",
    "    outputs_spa, final_state_spa = tf.nn.dynamic_rnn(mlstm_cell_spa, X_spa, initial_state=init_state_spa, time_major=False)\n",
    "    \n",
    "    attention_output_spa = fc_attention_sum(outputs_spa, fc_attention_size)\n",
    "    if attention == True:\n",
    "        attention_output_spa = tf.layers.batch_normalization(attention_output_spa)\n",
    "        return attention_output_spa\n",
    "    else:\n",
    "        outputs_spa = tf.layers.batch_normalization(outputs_spa)\n",
    "        outputs_spa = tf.reduce_sum(outputs_spa,axis = 1)\n",
    "        return outputs_spa\n",
    "\n",
    "def CONV_LSTM(conv_img,shape,attention):#(60,1024)\n",
    "    img_cell = ConvLSTMCell(shape, filters, kernel)\n",
    "    #conv_img shape (?, 40, 7, 7, 512)\n",
    "    img_outputs, img_state = tf.nn.dynamic_rnn(img_cell, conv_img, dtype=conv_img.dtype, time_major=True)\n",
    "    #img_outputs shape (?, 40, 7, 7, 1024)\n",
    "    #attention_kernel shape (1,1)\n",
    "    if attention == True: \n",
    "        img_attention_output = conv_attention_sum(img_outputs, attention_kernel)#[B,H,W,C] (?, 7, 7, 1024) remove the time_dims\n",
    "        img_attention_output = tf.layers.batch_normalization(img_attention_output)\n",
    "        return img_attention_output\n",
    "    else:\n",
    "        img_outputs = tf.layers.batch_normalization(img_outputs)\n",
    "        img_outputs = tf.reduce_sum(img_outputs,axis = 1)\n",
    "        return img_outputs  \n",
    "\n",
    "def FC_layer(inputs):#(60,1024)\n",
    "    weights2 =  tf.get_variable(\"xiangke\", [n_hidden_units, n_classes],initializer=tf.truncated_normal_initializer())\n",
    "    biases2 = tf.get_variable(\"kke\", [n_classes],initializer=tf.truncated_normal_initializer())\n",
    "    result = tf.nn.dropout((tf.matmul(inputs, weights2) + biases2), 0.5)\n",
    "    return result\n",
    "\n",
    "#fc_img_out = FC_LSTM(fc_img, True) #(60,1024)\n",
    "\n",
    "conv_img_out = CONV_LSTM(conv_img, shape_1,True)#(60,1024)\n",
    "\n",
    "#fc_img_drop = tf.nn.dropout(fc_img_out, 0.5)\n",
    "conv_img_drop = tf.nn.dropout(conv_img_out, 0.5)\n",
    "conv_img_drop = tf.nn.max_pool(conv_img_drop,[1,7,7,1],[1,1,1,1],padding='VALID')\n",
    "conv_img_drop = tf.reshape(conv_img_drop,[-1,filters])\n",
    "\n",
    "with tf.variable_scope(\"FC\"):\n",
    "    #fc_result = FC_layer(fc_img_drop)\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    conv_result = FC_layer(conv_img_drop)\n",
    "\n",
    "#fc_pred = tf.nn.softmax(fc_result)\n",
    "conv_pred = tf.nn.softmax(conv_result)\n",
    "\n",
    "#fc_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=fc_result, labels=ys))\n",
    "conv_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=conv_result, labels=ys))\n",
    "#loss = fc_loss+conv_loss\n",
    "loss = conv_loss\n",
    "print(loss)\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(Lr).minimize(loss)\n",
    "\n",
    "config = tf.ConfigProto() \n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "if not os.path.exists('fc+conv_lstm_tmp_attention'):\n",
    "    os.mkdir('fc+conv_lstm_tmp_attention/')\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "init_op = tf.global_variables_initializer() \n",
    "sess.run(init_op)\n",
    "\n",
    "############################################start_training###########################################\n",
    "\"\"\"\n",
    "\n",
    "k = 0\n",
    "u = 0\n",
    "\n",
    "full_loss = []\n",
    "for l in range(1000):\n",
    "    lr = basic_lr\n",
    "    pbar = tqdm(total=((len_train//batch_size)+1))\n",
    "    for i in range((len_train//batch_size)+1):\n",
    "\n",
    "        batch_fc_img = np.zeros((10*batch_size,40,4096),dtype = np.float32)\n",
    "        batch_conv_img = np.zeros((10*batch_size,40,7,7,512),dtype = np.float32)\n",
    "        batch_labels = np.zeros((10*batch_size,n_classes),dtype = np.int8)\n",
    "\n",
    "\n",
    "        time1 = time.time()\n",
    "        k= 0\n",
    "        for j in range(i*batch_size,(i+1)*batch_size):\n",
    "            if j>=len_train:\n",
    "                j = random.randint(0,len_train-1)\n",
    "            one_hot=np.zeros((n_classes),dtype = np.int8)\n",
    "            line = train_lines[j]\n",
    "\n",
    "            video_name = line.split(\" \")[0]\n",
    "\n",
    "            video_class = str(line.split(\" \")[0]).split(\"_\")[1]\n",
    "            feature_name = video_name+\"_.h5\"\n",
    "\n",
    "\n",
    "            one_hot[label_dict[video_class]] = 1\n",
    "            label = np.expand_dims(one_hot,axis = 0)\n",
    "            label = label.repeat(10,axis=0)\n",
    "          \n",
    "            #fc_img_fea = fc_feature(feature_name)\n",
    "            import tensorflow as tf\n",
    "            fc_img_fea=tf.random_uniform([1,40,4096], minval=1.0, maxval=5.0, dtype=tf.float32)\n",
    "            fc_img_fea=np.random.randn(1,40,4096)\n",
    "            #conv_img_fea = conv_feature(feature_name)\n",
    "            conv_img_fea=tf.random_uniform([1,timesteps]+shape_1+[channels], minval=1.0, maxval=5.0, dtype=tf.float32)\n",
    "            conv_img_fea=np.random.randn(1,timesteps,shape_1[0],shape_1[1],channels)\n",
    "\n",
    "            batch_fc_img[n_num*k:n_num*k+n_num] = fc_img_fea\n",
    "    \n",
    "            batch_conv_img[n_num*k:n_num*k+n_num] = conv_img_fea\n",
    "            batch_labels[n_num*k:n_num*k+n_num] = label\n",
    "            k = k+1\n",
    "        \n",
    "        time2 = time.time()\n",
    "        print(\"batch_read_time:\", '{0:.2f}'.format(time2-time1),\"s\")\n",
    "        k = k+1\n",
    "        first,second = sess.run([fc_img_out,fc_img_out], feed_dict={\n",
    "            fc_img : batch_fc_img,#(60, 40, 4096)\n",
    "            conv_img : batch_conv_img,#(60, 40, 7, 7, 512)\n",
    "            ys : batch_labels,\n",
    "            Lr : lr\n",
    "        })\n",
    "        print(\"batch_loss:\",loss_)\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "    model_name = \"fc+conv_lstm_tmp_attention/\"+str(l)+\"epoch_model.ckpt\"\n",
    "    saver.save(sess, model_name)\n",
    "\n",
    "    print(\"successfully,start_test!\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
